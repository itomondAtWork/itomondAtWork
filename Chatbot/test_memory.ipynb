{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain Result: {'question': 'こんにちは。私の名前は伊藤です。', 'chat_history': [], 'answer': 'Answer: こんにちは、伊藤さん。どのようにお手伝いできますか？'}\n",
      "Query: こんにちは。私の名前は伊藤です。\n",
      "Response: Answer: こんにちは、伊藤さん。どのようにお手伝いできますか？\n",
      "\n",
      "Chain Result: {'question': '私の名前を教えてください。', 'chat_history': [('こんにちは。私の名前は伊藤です。', 'Answer: こんにちは、伊藤さん。どのようにお手伝いできますか？')], 'answer': 'Assistant: こんにちは、伊藤さん。私の名前はAssistantです。どのようにお手伝いできますか？'}\n",
      "Query: 私の名前を教えてください。\n",
      "Response: Assistant: こんにちは、伊藤さん。私の名前はAssistantです。どのようにお手伝いできますか？\n",
      "\n",
      "Chain Result: {'question': '先ほどの会話を覚えていますか？', 'chat_history': [('こんにちは。私の名前は伊藤です。', 'Answer: こんにちは、伊藤さん。どのようにお手伝いできますか？'), ('私の名前を教えてください。', 'Assistant: こんにちは、伊藤さん。私の名前はAssistantです。どのようにお手伝いできますか？')], 'answer': 'Assistant: はい、私は先ほどの会話を覚えています。あなたの名前は伊藤さんとおっしゃっていました。'}\n",
      "Query: 先ほどの会話を覚えていますか？\n",
      "Response: Assistant: はい、私は先ほどの会話を覚えています。あなたの名前は伊藤さんとおっしゃっていました。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from hdbcli import dbapi\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 環境変数の読み込み\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def get_token():\n",
    "    auth_url = os.getenv('AICORE_AUTH_URL')\n",
    "    client_id = os.getenv('AICORE_CLIENT_ID')\n",
    "    client_secret = os.getenv('AICORE_CLIENT_SECRET')\n",
    "\n",
    "    token_url = f\"{auth_url}/oauth/token\"\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret\n",
    "    }\n",
    "\n",
    "    response = requests.post(token_url, data=data)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    token = response.json().get('access_token')\n",
    "    if not token:\n",
    "        raise ValueError(\"トークンが取得できませんでした。\")\n",
    "    return token\n",
    "\n",
    "def connect_database(proxy_client):\n",
    "    connection = dbapi.connect(\n",
    "        address=os.getenv(\"HANA_DB_ADDRESS\"),\n",
    "        port=os.getenv(\"HANA_DB_PORT\"),\n",
    "        user=os.getenv(\"HANA_DB_USER\"),\n",
    "        password=os.getenv(\"HANA_DB_PASSWORD\"),\n",
    "        autocommit=True,\n",
    "        sslValidateCertificate=False,\n",
    "    )\n",
    "    embeddings = OpenAIEmbeddings(deployment_id=os.getenv('EMBEDDING_DEPLOYMENT_ID'), proxy_client=proxy_client)\n",
    "    db = HanaDB(\n",
    "        connection=connection,\n",
    "        embedding=embeddings,\n",
    "        table_name=\"FILE_EMBEDDINGS\",\n",
    "    )\n",
    "    return db\n",
    "\n",
    "token = get_token()\n",
    "proxy_client = get_proxy_client('gen-ai-hub', token=token)\n",
    "db = connect_database(proxy_client)\n",
    "\n",
    "# LLMの定義\n",
    "llm = ChatOpenAI(deployment_id=os.getenv('LLM_DEPLOYMENT_ID'), proxy_client=proxy_client)\n",
    "\n",
    "# チェーンの設定\n",
    "def setup_chain(llm, db):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a helpful advisor. Context related to the prompt is provided.\n",
    "    Please answer it by referring to the chat history, but also referring to the following context.\n",
    "    ```\n",
    "    {context}\n",
    "    ```\n",
    "    Chat History: {chat_history}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"chat_history\", \"question\"]\n",
    "    )\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        retriever=db.as_retriever(),\n",
    "        verbose=False,\n",
    "        combine_docs_chain_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "# チャットの実行\n",
    "def run_conversational_chat(chain, query, chat_history):\n",
    "    # チェーンにクエリを投げて結果を取得\n",
    "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "    print(\"Chain Result:\", result)\n",
    "\n",
    "    # 新しいメッセージをチャット履歴に追加\n",
    "    chat_history.append((query, result.get(\"answer\", \"No valid response found\")))\n",
    "\n",
    "    # 結果を返す\n",
    "    return result.get(\"answer\", \"No valid response found\")\n",
    "\n",
    "# テストコード\n",
    "if __name__ == \"__main__\":\n",
    "    chain = setup_chain(llm, db)\n",
    "\n",
    "    # テストメッセージ\n",
    "    queries = [\n",
    "        \"こんにちは。私の名前は伊藤です。\",\n",
    "        \"私の名前を教えてください。\",\n",
    "        \"先ほどの会話を覚えていますか？\"\n",
    "    ]\n",
    "\n",
    "    chat_history = []\n",
    "\n",
    "    for query in queries:\n",
    "        response = run_conversational_chat(chain, query, chat_history)\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'question': 'こんにちは。私の名前は伊藤です。', 'chat_history': [HumanMessage(content='こんにちは。私の名前は伊藤です。'), AIMessage(content='Answer: こんにちは伊藤さん、何をお手伝いできるでしょうか？')], 'answer': 'Answer: こんにちは伊藤さん、何をお手伝いできるでしょうか？'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: こんにちは伊藤さん、何をお手伝いできるでしょうか？'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
