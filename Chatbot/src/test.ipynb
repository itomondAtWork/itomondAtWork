{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from hdbcli import dbapi\n",
    "from dotenv import load_dotenv\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# トークンを取得する関数\n",
    "def get_token():\n",
    "    auth_url = os.getenv('AICORE_AUTH_URL')\n",
    "    client_id = os.getenv('AICORE_CLIENT_ID')\n",
    "    client_secret = os.getenv('AICORE_CLIENT_SECRET')\n",
    "\n",
    "    token_url = f\"{auth_url}/oauth/token\"\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret\n",
    "    }\n",
    "\n",
    "    response = requests.post(token_url, data=data)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    token = response.json().get('access_token')\n",
    "    if not token:\n",
    "        raise ValueError(\"トークンが取得できませんでした。\")\n",
    "    return token\n",
    "\n",
    "# データベースに接続する関数\n",
    "def connect_database(proxy_client):\n",
    "    try:\n",
    "        connection = dbapi.connect(\n",
    "            address=os.getenv(\"HANA_DB_ADDRESS\"),\n",
    "            port=int(os.getenv(\"HANA_DB_PORT\")),  # ポートは整数に変換\n",
    "            user=os.getenv(\"HANA_DB_USER\"),\n",
    "            password=os.getenv(\"HANA_DB_PASSWORD\"),\n",
    "            autocommit=True,\n",
    "            sslValidateCertificate=False,\n",
    "        )\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        embeddings = OpenAIEmbeddings(deployment_id=os.getenv('EMBEDDING_DEPLOYMENT_ID'), proxy_client=proxy_client)\n",
    "        db = HanaDB(\n",
    "            connection=connection,\n",
    "            embedding=embeddings,\n",
    "            table_name=\"FILE_EMBEDDINGS\",\n",
    "        )\n",
    "        print(\"Database embeddings setup successful.\")\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database or setting up embeddings:\", e)\n",
    "        return None\n",
    "\n",
    "# チェーンを設定する関数\n",
    "def setup_chain(db, proxy_client):\n",
    "    llm = ChatOpenAI(deployment_id=os.getenv('LLM_DEPLOYMENT_ID'), proxy_client=proxy_client)\n",
    "    prompt_template = \"\"\"\n",
    "    You are a helpful advisor. Context related to the prompt is provided.\n",
    "    Please answer it by referring to the chat history, but also referring to the following context.\n",
    "    ```\n",
    "    {context}\n",
    "    ```\n",
    "    Chat History: {chat_history}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"chat_history\", \"question\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        retriever = db.as_retriever()\n",
    "        print(\"Retriever setup successful.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error setting up retriever:\", e)\n",
    "        return None\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        verbose=True,  # デバッグのためverboseをTrueに設定\n",
    "        combine_docs_chain_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "# チャットを実行する関数\n",
    "def run_conversational_chat(chain, query, chat_history):\n",
    "    print(\"Running query:\", query)\n",
    "    print(\"Chat History:\", chat_history)\n",
    "\n",
    "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "    print(\"Chain result:\", result)\n",
    "\n",
    "    chat_history.append((query, result.get(\"answer\", \"No valid response found\")))\n",
    "    \n",
    "    if \"context\" in result:\n",
    "        print(\"Context used:\", result[\"context\"])\n",
    "    else:\n",
    "        print(\"No context used\")\n",
    "\n",
    "    return result.get(\"answer\", \"No valid response found\")\n",
    "\n",
    "# 実行部分\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    token = get_token()\n",
    "    proxy_client = get_proxy_client('gen-ai-hub', token=token)\n",
    "\n",
    "    db = connect_database(proxy_client)\n",
    "\n",
    "    if db:\n",
    "        query = \"Expanded EditionのProduct Specialistについて、少しでも情報があるファイル名を全て教えてください。拡張子はそれぞれなんですか？\"\n",
    "        results = db.similarity_search(query, k=2)\n",
    "        print(\"Similarity Search Results:\", results)\n",
    "\n",
    "        for doc in results:\n",
    "            print(\"Document Content:\", doc.page_content)\n",
    "            print(\"Document Metadata:\", doc.metadata)\n",
    "\n",
    "        chain = setup_chain(db, proxy_client)\n",
    "\n",
    "        if chain:\n",
    "            chat_history = []\n",
    "            answer = run_conversational_chat(chain, query, chat_history)\n",
    "            print(\"Answer:\", answer)\n",
    "        else:\n",
    "            print(\"Failed to set up the chain.\")\n",
    "    else:\n",
    "        print(\"Failed to set up the database.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
