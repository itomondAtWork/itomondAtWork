{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start Langchain (Ver 0.1.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# initialize the model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.2,\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing by providing language testing services to assess the language proficiency of individuals or groups. This can include standardized language proficiency tests, custom language assessments, and language placement tests. Langsmith can also provide scoring and reporting services to help organizations and institutions make informed decisions based on the language test results. Additionally, Langsmith can offer test preparation materials and resources to help individuals and groups prepare for language proficiency exams.', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 15, 'total_tokens': 99}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_77a673219d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7820d7d3-f01d-4703-ab35-fc24bdc5cdf2-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It was supposed to be not good enough response, but this is something that wasn't present in the training data so it has a good response.\n",
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’d like to add something with using prompts\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "        \"system\",\n",
    "        \"You are world class technical documentation writer, so please tell me in one clear, concise sentence.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing by providing automated testing tools and frameworks to streamline the testing process and improve the efficiency and accuracy of testing activities.', response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 38, 'total_tokens': 66}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_77a673219d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ae38e3bc-3364-4093-8b93-b4ff4b692cb5-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# We can now combine these into a simple LLM chain:\n",
    "chain = prompt | llm\n",
    "chain.invoke([HumanMessage(content=\"how can langsmith help with testing?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by providing automated language translation and localization testing services to ensure the accuracy and quality of translated content.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output only text\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain_strOutput = prompt | llm | output_parser\n",
    "chain_strOutput.invoke([HumanMessage(content=\"How can langsmith help with testing?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SAP HANA Cloud Vector Engine\n",
    "\n",
    "https://how.wtf/how-to-use-json-files-in-vector-stores-with-langchain.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install necessary package\n",
    "!pip install --upgrade --quiet  hdbcli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection to a HANA Cloud instance.\n",
    "from hdbcli import dbapi\n",
    "load_dotenv()\n",
    "\n",
    "# Use connection settings from the environment\n",
    "connection = dbapi.connect(\n",
    "    address=os.getenv(\"HANA_DB_ADDRESS\"),\n",
    "    port=os.getenv(\"HANA_DB_PORT\"),\n",
    "    user=os.getenv(\"HANA_DB_USER\"),\n",
    "    password=os.getenv(\"HANA_DB_PASSWORD\"),\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    "    # currentSchema=\"HOTEL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "loader = JSONLoader(file_path=\"./Data/書誌情報ダウンロード(JSON形式)_20240418134938.json\", jq_schema=\".[] | .title[].value\", text_content=False)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 518 ms, total: 3.67 s\n",
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "# embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "# embedding = ErnieEmbeddings()\n",
    "embedding = CohereEmbeddings(model=\"embed-multilingual-light-v3.0\")\n",
    "\n",
    "# Access the vector DB with a new table\n",
    "db = HanaDB(\n",
    "    connection=connection,\n",
    "    embedding=embedding,\n",
    "    table_name=\"ITO_DEMO_RETRIEVAL_CHAIN\",\n",
    ")\n",
    "\n",
    "# Delete already existing entries from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks from the file\n",
    "db.add_documents(text_chunks)\n",
    "\n",
    "# # Create a retriever instance of the vector store\n",
    "# retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Based on the following JSON file, answer up to 10 titles similar to the book title provided by the user in a list format in order of similarity:: \\nn{context}, Question the title of the book.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, question_answering_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ChatMessageHistory\n",
    "# question = \"日本語ワープロ検定試験模擬問題集\"\n",
    "# chat_history = ChatMessageHistory()\n",
    "# chat_history.add_user_message(question)\n",
    "\n",
    "# document_chain.invoke(\n",
    "#     {\n",
    "#         \"messages\": chat_history.messages,\n",
    "#         \"context\": retriever.invoke(question),\n",
    "#     }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全国通訳案内士試験合格!対策地理 ,\n",
      "情報セキュリティマネジメント予想問題集 ,\n",
      "1週間で日商簿記3級に合格できるテキスト&問題集 : 書いて覚えて合格できる ,\n",
      "地方自治法よく出る問題123問 : 頻出テーマを徹底分析/実戦力・問題対応力養成 ,\n",
      "日本一わかりやすい地方創生の教科書 : 全く新しい45の新手法&新常識 : テレワーク 移住促進 インバウンド ,\n",
      "地方公務員法よく出る問題108問 : 頻出テーマを徹底分析/実戦力・問題対応力養成 ,\n",
      "スッキリわかるサーブレット&JSP入門 ,\n",
      "THE突破ファイルマンガ推理クイズブック ,\n",
      "もぐら〈仮〉 ,\n",
      "中学受験をするきみへ : 決定版 : 勉強とメンタルの悩みを解決! ,\n",
      "「生きる力を引き出す」住まい : 障がいをもつ方のくらしと家づくり : パーソンデザインで考えるくらしを変える福祉住環境 ,\n",
      "航西日記 : パリ万国博見聞録 : 現代語訳 ,\n",
      "できる江戸時代の世界を作ろう!マインクラフト和風建築わくわくスゴ技ブック ,\n",
      "ムツゴロウ麻雀物語 ,\n",
      "幼稚園WARS ,\n",
      "仕事と人間 : 70万年のグローバル労働史 ,\n",
      "打田十紀夫フィンガースタイル・ギター・メソッド : 基本演習と実践曲 ,\n",
      "トキワ荘の遺伝子 : 北見けんいちが語る巨匠たちの横顔 ,\n",
      "音旅のキセキ : 日本で新たな人生を見つけた音楽家の、誰も知らなかった素顔 : マーティ・フリードマン自叙伝 ,\n",
      "真実の口 ,\n",
      "AIが答えを出せない問いの設定力 ,\n",
      "新しい英検の教科書 ,\n",
      "放浪・雪の夜 : 織田作之助傑作集 ,\n",
      "クイズあなたは小学5年生より賢いの? : 大人もパニックの難問に挑戦! ,\n",
      "今日から始めて来月収穫!マンガでわかる!ズボラ野菜づくり ,\n",
      "植物の謎 : 60のQ&Aから見える、強くて緻密な生きざま ,\n",
      "肉ビジネス : 食べるのが好きな人から専門家まで楽しく読める肉の教養 ,\n",
      "中学受験奇跡を引き出す合格法則 : 予約殺到の東大卒スーパー家庭教師が教える ,\n",
      "エンターテインメント・ビジネス : 産業構造と契約実務 ,\n",
      "オンラインセラピーの理論と実践 : インターネットを通じた個人・集団・家族・組織への介入 ,\n",
      "ヤバすぎる!偉人の勉強やり方図鑑 ,\n",
      "ゴルゴ13スピンオフシリーズ : さいとう・プロ作品 ,\n",
      "調教師になったトップ・ジョッキー : 2500勝騎手がたどりついた「競馬の真実」 ,\n",
      "はじめてでも大収穫!野菜づくり超入門 ,\n",
      "浮・遊・感・覚 : 梓義朗作品集 ,\n",
      "遊☆戯☆王OCGストラクチャーズ ,\n",
      "基本情報技術者教科書 ,\n",
      "わしの研究 ,\n",
      "中学受験子どもの人生を本気で考えた受験校選び戦略 ,\n",
      "私の作家評伝 ,\n",
      "パケットキャプチャ無線LAN編 : Wiresharkによる解析 ,\n",
      "似合う!がわかる骨格診断の教科書 : 骨格診断アドバイザー検定2級・1級公式テキスト ,\n",
      "新・ちいさいひと : 青葉児童相談所物語 ,\n",
      "いちばん親切な練り切りの教科書 : 12か月の和菓子手帖 ,\n",
      "文豪ストレイドッグス太宰、中也、十五歳 ,\n",
      "ドラえもん学びワールドspecialはじめての料理 ,\n",
      "美しい文字は脳がつくる!永久美文字レッスン ,\n",
      "声と文字の人類学 ,\n",
      "NVC非暴力コミュニケーションワークブック : 親と子どもが心でつながる「キリン語」の子育て ,\n",
      "真説ゲームクリエイター伝 ,\n",
      "できるYouTuber式Excel現場の教科書 ,\n",
      "ゆる鉄絶景100 : 中井精也写真集 ,\n",
      "ジャジャ : For Moratorium Riders ,\n",
      "訪問介護で「できること」「できないこと」 : イラストと事例でわかる!あいまいゾーン : 90の事例をQ&Aでわかりやすく解説! ,\n",
      "VR浮遊館の謎 : 探偵AIのリアル・ディープラーニング ,\n",
      "東京ミドル期シングルの衝撃 : 「ひとり」社会のゆくえ ,\n",
      "ロト7&ロト6&ミニロトビッグデータ ,\n",
      "世界一細かすぎる筋トレストレッチ図鑑 ,\n",
      "少女小説とSF ,\n",
      "92歳、広岡達朗の正体 ,\n",
      "レッドブルー ,\n",
      "命の教科書 : 東大クイズ王医師×聖路加救急医療チームが伝える!『もしも』のときの基礎知識 ,\n",
      "これで通じる!最速最短でネイティブ発音になれる本 ,\n",
      "殺人小説大募集!! ,\n",
      "カミガカリ ,\n",
      "故事成語ツッコミ事典 : もしも言葉のレビューサイトがあったら ,\n",
      "青春2周目の俺がやり直す、ぼっちな彼女との陽キャな夏 ,\n",
      "とらわれ花姫の幸せな誤算 ,\n",
      "標準マクロ経済学 ,\n",
      "大江戸恋情本繁昌記 : 天の地本 ,\n",
      "花のようせい : 12か月 ,\n",
      "めおと旅籠繁盛記 ,\n",
      "門出の凶刃 : 引越し侍 ,\n",
      "ふくしま式で身につく!国語読解力 : 塾へ行かなくても得点力がぐ～んと上がる! ,\n",
      "AI法廷の弁護士 ,\n",
      "かがやけ!ミラクルボーイズ : 始まりのキセキ ,\n",
      "間違いだらけの健康常識 ,\n",
      "Ωの正しい征服法 ,\n",
      "分子科学者がやさしく解説する地球温暖化Q&A181 : 熱・温度の正体から解き明かす ,\n",
      "マイホームヒーロー ,\n",
      "カメリア : 山崎真実ラスト写真集 ,\n",
      "志高く : 孫正義正伝 ,\n",
      "パリピ孔明 ,\n",
      "くらべてわかるサメ ,\n",
      "僕のカノジョ先生 ,\n",
      "ミラクルラブリー・感動のどうぶつ物語DX : キミとの奇跡 ,\n",
      "コスモVS! ,\n",
      "100日でネイティブのように話せる韓国語文法 ,\n",
      "告白～コンフェッション～ ,\n",
      "ラストカルテ : 法獣医学者当麻健匠の記憶 ,\n",
      "岩元先輩ノ推薦 ,\n",
      "3年3組田中太郎 ,\n",
      "センスのいい部屋、74人のアイデア。 ,\n",
      "近代日本の陽明学 ,\n",
      "蒼く染めろ ,\n",
      "最強の詩 ,\n",
      "イトミミズ ,\n",
      "スッキリ出る!直腸ストレッチ : 一日3分で「出口の詰まり」を取って便秘を解消するセルフケア ,\n",
      "美龍艶笑譚 : 自己肯定感が激低なドラゴン級美少女魔王を、勇者がイチャラブで退治するお話 ,\n",
      "カードキャプターさくら ,\n",
      "CPU times: user 64 ms, sys: 9.78 ms, total: 73.8 ms\n",
      "Wall time: 689 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"日本語ワープロ検定試験模擬問題集\"\n",
    "docs = db.similarity_search(question, k=100)\n",
    "for doc in docs:\n",
    "    print(doc.page_content,\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    document_chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"messages\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Ito is the one who took action on these minutes. What version of LangChain did Mr. Ito use before?\"\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "chain_with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": chat_history.messages,\n",
    "        \"context\": retriever.invoke(question)\n",
    "    },\n",
    "    {'configurable': {'session_id': 'unused'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did I just ask you?\"\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "chain_with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": chat_history.messages,\n",
    "        \"context\": retriever.invoke(question)\n",
    "    },\n",
    "    {'configurable': {'session_id': 'unused'}}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
