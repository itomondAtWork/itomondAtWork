{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは、Generative AI Hub SDK の公式ドキュメント[https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/_reference/README_sphynx.html]に従って操作する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数の読み込み\n",
    "from dotenv import load_dotenv\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"Hello, World!\"),\n",
    "]\n",
    "\n",
    "chat_llm = ChatOpenAI(deployment_id='deb90f258a38f739')\n",
    "chat_llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ Notebook Cell 2\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(deployment_id='d6835c4c6c0da6e6')\n",
    "\n",
    "single_vector = embedding_model.embed_query(\"Hello world\")\n",
    "print(str(single_vector)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ Notebook Cell 3\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper(k=5) # return top‑5 results\n",
    "\n",
    "google_tool = Tool.from_function(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google and return the first results\",\n",
    "    func=search.run\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ Notebook Cell 4\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[google_tool],\n",
    "    llm=chat_llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent.invoke(\"Who won the Tokyo Marathon in 2025, and what was the finishing time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ Notebook Cell 5\n",
    "import random\n",
    "\n",
    "def omikuji(_: str) -> str:\n",
    "    return random.choice([\n",
    "        \"XXXXXX\"\n",
    "    ])\n",
    "\n",
    "omikuji_tool = Tool.from_function(\n",
    "    name=\"xxxxxx\",\n",
    "    description=\"......\",\n",
    "    # ?????\n",
    ")\n",
    "\n",
    "omikuji_agent = initialize_agent(\n",
    "    tools=XXXXXXXX,\n",
    "    llm=chat_llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "omikuji_agent.invoke(\"おみくじを引いてください\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ Notebook Cell 6\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from hdbcli import dbapi\n",
    "\n",
    "load_dotenv()\n",
    "# Use connection settings from the environment\n",
    "connection = dbapi.connect(\n",
    "    address=os.environ.get(\"HANA_DB_ADDRESS\"),\n",
    "    port=os.environ.get(\"HANA_DB_PORT\"),\n",
    "    user=os.environ.get(\"HANA_DB_USER\"),\n",
    "    password=os.environ.get(\"HANA_DB_PASSWORD\"),\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-hana\n",
      "  Downloading langchain_hana-0.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: hdbcli<3.0.0,>=2.23.24 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-hana) (2.24.24)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-hana) (0.3.52)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain-hana)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: langsmith<0.4,>=0.1.125 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (0.3.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-hana) (2.9.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-hana) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-hana) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-hana) (2.23.4)\n",
      "Requirement already satisfied: anyio in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (1.0.8)\n",
      "Requirement already satisfied: idna in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (3.10)\n",
      "Requirement already satisfied: sniffio in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Agent_Streamlit_venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-hana) (2.4.0)\n",
      "Downloading langchain_hana-0.1.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl size=4728956 sha256=94d8bdd25ebf46256c9312489157522ec03edb151ff9ff7087a7d58f06fbf7ef\n",
      "  Stored in directory: /Users/I742374/Library/Caches/pip/wheels/8b/2d/9f/b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "Successfully built numpy\n",
      "Installing collected packages: numpy, langchain-hana\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "Successfully installed langchain-hana-0.1.0 numpy-1.26.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-hana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana import HanaInternalEmbeddings\n",
    "\n",
    "embeddings = HanaInternalEmbeddings(internal_embedding_model_id=\"SAP_NEB.20240715\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana import HanaDB\n",
    "\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=\"STATE_OF_THE_UNION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 286\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import TextSplitter\n",
    "\n",
    "text_documents = TextLoader(\n",
    "    \"state_of_the_union.txt\"\n",
    ").load()\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \". \",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 0,  # チャンクオーバーラップの文字数\n",
    ")\n",
    "text_chunks = text_splitter.split_documents(text_documents)\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "We pledge historic resources toward education, to ensure the promise of America reaches every doorstep. In the face of unprecedented challenges, we boldly pursue global leadership. Our administration will champion democracy, so that tomorrow's breakthroughs are born on our shores. My fellow citizens, it is with determination that we strive for prosperity. Across every state, communities are already embracing democracy, to ensure the promise of America reaches every doorstep. This year, united as one people, we set our sights on security. Across every state, communities are already embracing energy, to secure a future worthy of our proud history. This year, united as one people, we set our sights on science. We pledge historic resources toward opportunity, to secure a future worthy of our proud history. This year, united as one people, we set our sights on freedom. Across every state, communities are already embracing justice, to secure a future worthy of our proud history\n",
      "--------------------------------------------------------------------------------\n",
      "Our administration will champion security, to ensure the promise of America reaches every doorstep. This year, united as one people, we set our sights on community. Across every state, communities are already embracing opportunity, to secure a future worthy of our proud history. My fellow citizens, it is with determination that we strive for community. We pledge historic resources toward opportunity, to ensure the promise of America reaches every doorstep. My fellow citizens, it is with determination that we strive for global leadership. Together, we will invest in security, because the strength of our union depends on no one being left behind. Our story is one of relentless progress toward healthcare. Across every state, communities are already embracing justice, because the strength of our union depends on no one being left behind. My fellow citizens, it is with determination that we strive for climate resilience\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query, k=2)\n",
    "\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent_Streamlit_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
